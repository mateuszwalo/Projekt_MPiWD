]
# Zapisujemy oczyszczoną kopię danych
output_path = 'simplified_data.csv'
simplified_data.to_csv(output_path, index=False)
import pandas as pd
file_path = '/mnt/data/public_emdat_custom_request_2024-10-03_fdbbae24-da6c-4137-b8d4-3c5548a622df.xlsx'
raw_data = pd.ExcelFile(file_path)
raw_data = raw_data.parse('EM-DAT Data')
#Kluczowe kolumny do analizy
key_columns = [
'Disaster Type', 'Country', 'Region', 'Start Year', 'Start Month', 'End Year', 'End Month',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude'
]
# Zachowaj tylko wybrane kolumny
cleaned_data = raw_data[key_columns]
#Uzupełniamy występujące braki
numerical_columns = ['Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude']
cleaned_data[numerical_columns] = cleaned_data[numerical_columns].fillna(0)
categorical_columns = ['Disaster Type', 'Country', 'Region']
cleaned_data[categorical_columns] = cleaned_data[categorical_columns].fillna('Unknown')
#Konwersja dat do prawidłowego formatu
cleaned_data['Start Date'] = pd.to_datetime(
cleaned_data['Start Year'].astype(str) + '-' +
cleaned_data['Start Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
cleaned_data['End Date'] = pd.to_datetime(
cleaned_data['End Year'].astype(str) + '-' +
cleaned_data['End Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
# Uproszczenie zbioru danych
simplified_data = cleaned_data[
['Disaster Type', 'Country', 'Region', 'Start Date', 'End Date',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)',
'Latitude', 'Longitude']
]
# Zapisujemy oczyszczoną kopię danych
output_path = 'C:\STUDIA MATERIAŁY\Semestr III\MPiWD\Projekt_MPiWD_Walo_Mateusz\simplified_data.csv'
simplified_data.to_csv(output_path, index=False)
import pandas as pd
file_path = 'public_emdat_custom_request_2024-10-03_fdbbae24-da6c-4137-b8d4-3c5548a622df.xlsx'
raw_data = pd.ExcelFile(file_path)
raw_data = raw_data.parse('EM-DAT Data')
#Kluczowe kolumny do analizy
key_columns = [
'Disaster Type', 'Country', 'Region', 'Start Year', 'Start Month', 'End Year', 'End Month',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude'
]
# Zachowaj tylko wybrane kolumny
cleaned_data = raw_data[key_columns]
#Uzupełniamy występujące braki
numerical_columns = ['Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude']
cleaned_data[numerical_columns] = cleaned_data[numerical_columns].fillna(0)
categorical_columns = ['Disaster Type', 'Country', 'Region']
cleaned_data[categorical_columns] = cleaned_data[categorical_columns].fillna('Unknown')
#Konwersja dat do prawidłowego formatu
cleaned_data['Start Date'] = pd.to_datetime(
cleaned_data['Start Year'].astype(str) + '-' +
cleaned_data['Start Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
cleaned_data['End Date'] = pd.to_datetime(
cleaned_data['End Year'].astype(str) + '-' +
cleaned_data['End Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
# Uproszczenie zbioru danych
simplified_data = cleaned_data[
['Disaster Type', 'Country', 'Region', 'Start Date', 'End Date',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)',
'Latitude', 'Longitude']
]
# Zapisujemy oczyszczoną kopię danych
output_path = 'C:\STUDIA MATERIAŁY\Semestr III\MPiWD\Projekt_MPiWD_Walo_Mateusz\simplified_data.csv'
simplified_data.to_csv(output_path, index=False)
pip install openpyxl
import pandas as pd
!pip install openpyxl
file_path = 'public_emdat_custom_request_2024-10-03_fdbbae24-da6c-4137-b8d4-3c5548a622df.xlsx'
raw_data = pd.read(file_path)
raw_data = raw_data.parse('EM-DAT Data')
#Kluczowe kolumny do analizy
key_columns = [
'Disaster Type', 'Country', 'Region', 'Start Year', 'Start Month', 'End Year', 'End Month',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude'
]
# Zachowaj tylko wybrane kolumny
cleaned_data = raw_data[key_columns]
#Uzupełniamy występujące braki
numerical_columns = ['Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude']
cleaned_data[numerical_columns] = cleaned_data[numerical_columns].fillna(0)
categorical_columns = ['Disaster Type', 'Country', 'Region']
cleaned_data[categorical_columns] = cleaned_data[categorical_columns].fillna('Unknown')
#Konwersja dat do prawidłowego formatu
cleaned_data['Start Date'] = pd.to_datetime(
cleaned_data['Start Year'].astype(str) + '-' +
cleaned_data['Start Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
cleaned_data['End Date'] = pd.to_datetime(
cleaned_data['End Year'].astype(str) + '-' +
cleaned_data['End Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
# Uproszczenie zbioru danych
simplified_data = cleaned_data[
['Disaster Type', 'Country', 'Region', 'Start Date', 'End Date',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)',
'Latitude', 'Longitude']
]
# Zapisujemy oczyszczoną kopię danych
output_path = 'C:\STUDIA MATERIAŁY\Semestr III\MPiWD\Projekt_MPiWD_Walo_Mateusz\simplified_data.csv'
simplified_data.to_csv(output_path, index=False)
View(file_path)
raw_data = pd.read(file_path)
raw_data = pd.ExcelFile(file_path)
View(raw_data)
import pandas as pd
file_path = 'public_emdat_custom_request_2024-10-03_fdbbae24-da6c-4137-b8d4-3c5548a622df.xlsx'
raw_data = pd.ExcelFile(file_path)
raw_data = raw_data.parse('EM-DAT Data')
#Kluczowe kolumny do analizy
key_columns = [
'Disaster Type', 'Country', 'Region', 'Start Year', 'Start Month', 'End Year', 'End Month',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude'
]
# Zachowaj tylko wybrane kolumny
cleaned_data = raw_data[key_columns]
#Uzupełniamy występujące braki
numerical_columns = ['Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude']
cleaned_data[numerical_columns] = cleaned_data[numerical_columns].fillna(0)
categorical_columns = ['Disaster Type', 'Country', 'Region']
cleaned_data[categorical_columns] = cleaned_data[categorical_columns].fillna('Unknown')
#Konwersja dat do prawidłowego formatu
cleaned_data['Start Date'] = pd.to_datetime(
cleaned_data['Start Year'].astype(str) + '-' +
cleaned_data['Start Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
cleaned_data['End Date'] = pd.to_datetime(
cleaned_data['End Year'].astype(str) + '-' +
cleaned_data['End Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
# Uproszczenie zbioru danych
simplified_data = cleaned_data[
['Disaster Type', 'Country', 'Region', 'Start Date', 'End Date',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)',
'Latitude', 'Longitude']
]
# Zapisujemy oczyszczoną kopię danych
output_path = 'C:\STUDIA MATERIAŁY\Semestr III\MPiWD\Projekt_MPiWD_Walo_Mateusz\simplified_data.csv'
simplified_data.to_csv(output_path, index=False)
import pandas as pd
file_path = 'public_emdat_custom_request_2024-10-03_fdbbae24-da6c-4137-b8d4-3c5548a622df.xlsx'
raw_data = pd.ExcelFile(file_path)
raw_data = raw_data.parse('EM-DAT Data')
#Kluczowe kolumny do analizy
key_columns = [
'Classification Key','Disaster Subtype','Disaster Subgroup','Disaster Group','Disaster Type', 'Country', 'Region', 'Start Year', 'Start Month', 'End Year', 'End Month',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude'
]
# Zachowaj tylko wybrane kolumny
cleaned_data = raw_data[key_columns]
#Uzupełniamy występujące braki
numerical_columns = ['Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude']
cleaned_data[numerical_columns] = cleaned_data[numerical_columns].fillna(0)
categorical_columns = ['Disaster Type', 'Country', 'Region','Disaster Subtype','Disaster Subgroup','Disaster Group','Disaster Type']
cleaned_data[categorical_columns] = cleaned_data[categorical_columns].fillna('Unknown')
#Konwersja dat do prawidłowego formatu
cleaned_data['Start Date'] = pd.to_datetime(
cleaned_data['Start Year'].astype(str) + '-' +
cleaned_data['Start Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
cleaned_data['End Date'] = pd.to_datetime(
cleaned_data['End Year'].astype(str) + '-' +
cleaned_data['End Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
# Uproszczenie zbioru danych
simplified_data = cleaned_data[
['Disaster Type', 'Country', 'Region', 'Start Date', 'End Date',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)',
'Latitude', 'Longitude']
]
# Zapisujemy oczyszczoną kopię danych
output_path = 'C:\STUDIA MATERIAŁY\Semestr III\MPiWD\Projekt_MPiWD_Walo_Mateusz\simplified_data.csv'
simplified_data.to_csv(output_path, index=False)
df=pd.read_csv(output_path)
df.head()
import pandas as pd
file_path = 'public_emdat_custom_request_2024-10-03_fdbbae24-da6c-4137-b8d4-3c5548a622df.xlsx'
raw_data = pd.ExcelFile(file_path)
raw_data = raw_data.parse('EM-DAT Data')
#Kluczowe kolumny do analizy
key_columns = [
'Classification Key','Disaster Subtype','Disaster Subgroup','Disaster Group','Disaster Type', 'Country', 'Region', 'Start Year', 'Start Month', 'End Year', 'End Month','Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude'
]
# Zachowaj tylko wybrane kolumny
cleaned_data = raw_data[key_columns]
#Uzupełniamy występujące braki
numerical_columns = ['Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude']
cleaned_data[numerical_columns] = cleaned_data[numerical_columns].fillna(0)
categorical_columns = ['Disaster Type', 'Country', 'Region','Disaster Subtype','Disaster Subgroup','Disaster Group','Disaster Type']
cleaned_data[categorical_columns] = cleaned_data[categorical_columns].fillna('Unknown')
#Konwersja dat do prawidłowego formatu
cleaned_data['Start Date'] = pd.to_datetime(
cleaned_data['Start Year'].astype(str) + '-' +
cleaned_data['Start Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
cleaned_data['End Date'] = pd.to_datetime(
cleaned_data['End Year'].astype(str) + '-' +
cleaned_data['End Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
# Uproszczenie zbioru danych
simplified_data = cleaned_data[
['Disaster Type', 'Country', 'Region', 'Start Date', 'End Date',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)',
'Latitude', 'Longitude']
]
# Zapisujemy oczyszczoną kopię danych
output_path = 'C:\STUDIA MATERIAŁY\Semestr III\MPiWD\Projekt_MPiWD_Walo_Mateusz\simplified_data.csv'
simplified_data.to_csv(output_path, index=False)
df=pd.read_csv(output_path)
df.head()
quit
# Wczytanie bibliotek
library(ggplot2)
library(leaflet)
install.packages("leaflet")
reticulate::repl_python()
import pandas as pd
file_path = 'public_emdat_custom_request_2024-10-03_fdbbae24-da6c-4137-b8d4-3c5548a622df.xlsx'
# Wczytanie danych
raw_data = pd.ExcelFile(file_path)
raw_data = raw_data.parse('EM-DAT Data')
# Kluczowe kolumny do analizy
key_columns = [
'Classification Key', 'Disaster Subtype', 'Disaster Subgroup', 'Disaster Group','Disaster Type', 'Country', 'Region', 'Start Year', 'Start Month',
'End Year', 'End Month', 'Total Deaths', 'No. Injured', 'Total Affected',
'Total Damage (\'000 US$)', 'Latitude', 'Longitude'
]
# Zachowaj tylko wybrane kolumny
cleaned_data = raw_data[key_columns]
# Uzupełnianie braków danych
# Numeryczne wartości: braki zastąpione zerami z uwagi na specyfikację problemu
numerical_columns = ['Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude']
cleaned_data[numerical_columns] = cleaned_data[numerical_columns].fillna(0)
# Kategoryczne wartości: braki zastąpione 'Unknown'z uwagi na specyfikację problemu
categorical_columns = [
'Disaster Type', 'Country', 'Region', 'Disaster Subtype',
'Disaster Subgroup', 'Disaster Group', 'Classification Key'
]
cleaned_data[categorical_columns] = cleaned_data[categorical_columns].fillna('Unknown')
# Konwersja dat do prawidłowego formatu
cleaned_data['Start Date'] = pd.to_datetime(
cleaned_data['Start Year'].astype(str) + '-' +
cleaned_data['Start Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
cleaned_data['End Date'] = pd.to_datetime(
cleaned_data['End Year'].astype(str) + '-' +
cleaned_data['End Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
# Uproszczenie zbioru danych do najważniejszych kolumn
simplified_data = cleaned_data[
['Classification Key', 'Disaster Group', 'Disaster Subgroup', 'Disaster Subtype',
'Disaster Type', 'Country', 'Region', 'Start Date', 'End Date',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)',
'Latitude', 'Longitude']
]
#Zapisujemy kopię oczyszczoną na dysku
output_path = 'C:\\STUDIA MATERIAŁY\\Semestr III\\MPiWD\\Projekt_MPiWD_Walo_Mateusz\\simplified_data.csv'
simplified_data.to_csv(output_path, index=False)
df=pd.read_csv(output_path)
df.head()
quit
# Wczytanie bibliotek
library(ggplot2)
library(leaflet)
library(dplyr)
library(sf)
install.packages("sf")
reticulate::repl_python()
df=pd.read_csv(output_path)
quit
library(tidyverse)
kable(df)
# Wczytanie bibliotek
library(ggplot2)
library(leaflet)
library(dplyr)
library(sf)
# Wczytanie danych
data <- read.csv("simplified_data.csv")
# Konwersja dat
data$Start.Date <- as.Date(data$Start.Date)
data$End.Date <- as.Date(data$End.Date)
# Wizualizacja 1: Mapa interaktywna katastrof
leaflet(data) %>%
addTiles() %>%
addCircleMarkers(
~Longitude, ~Latitude,
color = ~ifelse(Disaster.Type == "Flood", "blue",
ifelse(Disaster.Type == "Earthquake", "red", "green")),
popup = ~paste0("<b>Disaster:</b> ", Disaster.Type,
"<br><b>Country:</b> ", Country,
"<br><b>Total Deaths:</b> ", Total.Deaths),
radius = ~log1p(Total.Affected) * 2,
stroke = FALSE, fillOpacity = 0.5
) %>%
addLegend(
"bottomright",
colors = c("blue", "red", "green"),
labels = c("Flood", "Earthquake", "Other"),
title = "Disaster Type"
)
# Wizualizacja 2: Liczba katastrof w czasie
data_by_year <- data %>%
mutate(Year = format(Start.Date, "%Y")) %>%
group_by(Year, Disaster.Type) %>%
summarize(Count = n(), .groups = "drop")
ggplot(data_by_year, aes(x = as.numeric(Year), y = Count, color = Disaster.Type)) +
geom_line(size = 1.2) +
geom_point(size = 3) +
theme_minimal() +
labs(
title = "Number of Disasters Over Time",
x = "Year",
y = "Count",
color = "Disaster Type"
)
# Wizualizacja 3: Globalny wpływ katastrof
world <- map_data("world")
install.packages("maps")
View(data)
reticulate::repl_python()
import pandas as pd
file_path = 'public_emdat_custom_request_2024-10-03_fdbbae24-da6c-4137-b8d4-3c5548a622df.xlsx'
# Wczytanie danych
raw_data = pd.ExcelFile(file_path)
raw_data = raw_data.parse('EM-DAT Data')
# Kluczowe kolumny do analizy
key_columns = [
'Classification Key', 'Disaster Subtype', 'Disaster Subgroup', 'Disaster Group','Disaster Type', 'Country', 'Region', 'Start Year', 'Start Month',
'End Year', 'End Month', 'Total Deaths', 'No. Injured', 'Total Affected',
'Total Damage (\'000 US$)', 'Latitude', 'Longitude'
]
# Zachowaj tylko wybrane kolumny
cleaned_data = raw_data[key_columns]
# Uzupełnianie braków danych
# Numeryczne wartości: braki zastąpione zerami z uwagi na specyfikację problemu
numerical_columns = ['Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude']
cleaned_data[numerical_columns] = cleaned_data[numerical_columns].fillna(0)
# Kategoryczne wartości: braki zastąpione 'Unknown'z uwagi na specyfikację problemu
categorical_columns = [
'Disaster Type', 'Country', 'Region', 'Disaster Subtype',
'Disaster Subgroup', 'Disaster Group', 'Classification Key'
]
cleaned_data[categorical_columns] = cleaned_data[categorical_columns].fillna('Unknown')
# Konwersja dat do prawidłowego formatu
cleaned_data['Start Date'] = pd.to_datetime(
cleaned_data['Start Year'].astype(str) + '-' +
cleaned_data['Start Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
cleaned_data['End Date'] = pd.to_datetime(
cleaned_data['End Year'].astype(str) + '-' +
cleaned_data['End Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
# Uproszczenie zbioru danych do najważniejszych kolumn
simplified_data = cleaned_data[
['Classification Key', 'Disaster Group', 'Disaster Subgroup', 'Disaster Subtype',
'Disaster Type', 'Country', 'Region', 'Start Date', 'End Date',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)',
'Latitude', 'Longitude']
]
#Zapisujemy kopię oczyszczoną na dysku
output_path = 'C:\\STUDIA MATERIAŁY\\Semestr III\\MPiWD\\Projekt_MPiWD_Walo_Mateusz\\simplified_data.csv'
simplified_data.to_csv(output_path, index=False)
data=pd.read_csv(output_path)
quit
library(tidyverse)
library(ggplot2)
library(leaflet)
library(dplyr)
library(sf)
library(tibble)
kable(df)
View(data)
kable(data)
library(tidyverse)
library(ggplot2)
library(leaflet)
library(dplyr)
library(sf)
library(tibble)
library(knitr)
kable(data)
kable(data)
reticulate::repl_python()
import pandas as pd
file_path = 'public_emdat_custom_request_2024-10-03_fdbbae24-da6c-4137-b8d4-3c5548a622df.xlsx'
# Wczytanie danych
raw_data = pd.ExcelFile(file_path)
raw_data = raw_data.parse('EM-DAT Data')
# Kluczowe kolumny do analizy
key_columns = [
'Classification Key', 'Disaster Subtype', 'Disaster Subgroup', 'Disaster Group','Disaster Type', 'Country', 'Region', 'Start Year', 'Start Month',
'End Year', 'End Month', 'Total Deaths', 'No. Injured', 'Total Affected',
'Total Damage (\'000 US$)', 'Latitude', 'Longitude'
]
# Zachowaj tylko wybrane kolumny
cleaned_data = raw_data[key_columns]
# Uzupełnianie braków danych
# Numeryczne wartości: braki zastąpione zerami z uwagi na specyfikację problemu
numerical_columns = ['Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)', 'Latitude', 'Longitude']
cleaned_data[numerical_columns] = cleaned_data[numerical_columns].fillna(0)
# Kategoryczne wartości: braki zastąpione 'Unknown'z uwagi na specyfikację problemu
categorical_columns = [
'Disaster Type', 'Country', 'Region', 'Disaster Subtype',
'Disaster Subgroup', 'Disaster Group', 'Classification Key'
]
cleaned_data[categorical_columns] = cleaned_data[categorical_columns].fillna('Unknown')
# Konwersja dat do prawidłowego formatu
cleaned_data['Start Date'] = pd.to_datetime(
cleaned_data['Start Year'].astype(str) + '-' +
cleaned_data['Start Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
cleaned_data['End Date'] = pd.to_datetime(
cleaned_data['End Year'].astype(str) + '-' +
cleaned_data['End Month'].fillna(1).astype(int).astype(str) + '-01',
errors='coerce'
)
# Uproszczenie zbioru danych do najważniejszych kolumn
simplified_data = cleaned_data[
['Classification Key', 'Disaster Group', 'Disaster Subgroup', 'Disaster Subtype',
'Disaster Type', 'Country', 'Region', 'Start Date', 'End Date',
'Total Deaths', 'No. Injured', 'Total Affected', 'Total Damage (\'000 US$)',
'Latitude', 'Longitude']
]
#Zapisujemy kopię oczyszczoną na dysku
output_path = 'C:\\STUDIA MATERIAŁY\\Semestr III\\MPiWD\\Projekt_MPiWD_Walo_Mateusz\\simplified_data.csv'
simplified_data.to_csv(output_path, index=False)
quit
library(tidyverse)
library(ggplot2)
library(leaflet)
library(dplyr)
library(sf)
library(tibble)
library(knitr)
data <- read.csv("simplified_data.csv")
# Wizualizacja 1: Mapa interaktywna katastrof
leaflet(data) %>%
addTiles() %>%
addCircleMarkers(
~Longitude, ~Latitude,
color = ~ifelse(Disaster.Type == "Flood", "blue",
ifelse(Disaster.Type == "Earthquake", "red", "green")),
popup = ~paste0("<b>Disaster:</b> ", Disaster.Type,
"<br><b>Country:</b> ", Country,
"<br><b>Total Deaths:</b> ", Total.Deaths),
radius = ~log1p(Total.Affected) * 2,
stroke = FALSE, fillOpacity = 0.5
) %>%
addLegend(
"bottomright",
colors = c("blue", "red", "green"),
labels = c("Flood", "Earthquake", "Other"),
title = "Disaster Type"
)
# Wizualizacja 2: Liczba katastrof w czasie
data_by_year <- data %>%
mutate(Year = format(Start.Date, "%Y")) %>%
group_by(Year, Disaster.Type) %>%
summarize(Count = n(), .groups = "drop")
# Wizualizacja 3: Globalny wpływ katastrof
world <- map_data("world")
ggplot() +
geom_map(data = world, map = world,
aes(x = long, y = lat, map_id = region),
fill = "gray90", color = "gray50", size = 0.3) +
geom_point(data = data, aes(x = Longitude, y = Latitude, size = Total.Affected, color = Disaster.Type),
alpha = 0.7) +
scale_size_continuous(range = c(2, 10), name = "Total Affected") +
theme_minimal() +
labs(
title = "Global Distribution of Disasters",
color = "Disaster Type"
)
library(tidyverse)
library(ggplot2)
library(leaflet)
library(dplyr)
library(sf)
library(tibble)
library(knitr)
library(rnaturalearth)
library(networkD3)
library(jsonlite)
library(gganimate)
data <- read.csv("simplified_data.csv")
head(data)
kable(data)
